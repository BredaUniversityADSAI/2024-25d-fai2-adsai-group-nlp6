{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a Model as an Endpoint \n",
    "\n",
    "### What is an Endpoint? 🤔\n",
    "\n",
    "Azureml allows you to deploy models as endpoints. This means that you can send data to the endpoint and get a prediction back. In order to do this, you need to create a scoring script that will be used to make predictions, and an endpoint configuration that will define the compute resources that will be used to serve the endpoint. \n",
    "\n",
    "We will be making use of the `KubernetesOnlineEndpoint` class to deploy the model as an endpoint. This class will deploy the model to the already running K8s cluster. The class will also create a service that will expose the model as an endpoint. We use this instead of the `ManagedOnlineEndpoint` class because the `ManagedOnlineEndpoint` class will create Azure compute instances to serve the endpoint, which is more expensive and less performant than using the already running K8s cluster. \n",
    "\n",
    "### Local Deployment 🏠\n",
    "\n",
    "We will begin by deploying the model locally. This is useful for testing the endpoint before deploying it to the cloud. It is also useful for debugging the endpoint, and for testing the endpoint with a small amount of data. It will make the deployment process faster and easier.\n",
    "\n",
    "First, we will create the endpoint configuration. This will define the compute resources that will be used to serve the endpoint.\n",
    "\n",
    "**_Note: The local deployment will only work if you have Docker installed on your machine, and the Docker daemon is running._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    KubernetesOnlineEndpoint,\n",
    "    KubernetesOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential, ClientSecretCredential\n",
    "from azure.ai.ml.entities._deployment.resource_requirements_settings import (\n",
    "    ResourceRequirementsSettings,\n",
    ")\n",
    "from azure.ai.ml.entities._deployment.container_resource_settings import (\n",
    "    ResourceSettings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Connect to the MLClient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"0a94de80-6d3b-49f2-b3e9-ec5818862801\"\n",
    "resource_group = \"buas-y2\"\n",
    "workspace_name = \"Staff-Test\"\n",
    "tenant_id = \"0a33589b-0036-4fe8-a829-3ed0926af886\"\n",
    "client_id = \"a2230f31-0fda-428d-8c5c-ec79e91a49f5\"\n",
    "client_secret = \"Y-q8Q~H63btsUkR7dnmHrUGw2W0gMWjs0MxLKa1C\"\n",
    "\n",
    "credential = ClientSecretCredential(tenant_id, client_id, client_secret)\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential, subscription_id, resource_group, workspace_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the endpoint configuration for the local deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a local endpoint\n",
    "import datetime\n",
    "\n",
    "local_endpoint_name = \"local-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = KubernetesOnlineEndpoint(\n",
    "    name=local_endpoint_name, description=\"this is a sample local endpoint\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating local endpoint: local-06201921868040\n"
     ]
    }
   ],
   "source": [
    "print(f\"Creating local endpoint: {local_endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install the docker package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docker in c:\\users\\soheil\\appdata\\local\\pypoetry\\cache\\virtualenvs\\emotion-clf-pipeline-boncazar-py3.11\\lib\\site-packages (7.1.0)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\soheil\\appdata\\local\\pypoetry\\cache\\virtualenvs\\emotion-clf-pipeline-boncazar-py3.11\\lib\\site-packages (from docker) (310)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\soheil\\appdata\\local\\pypoetry\\cache\\virtualenvs\\emotion-clf-pipeline-boncazar-py3.11\\lib\\site-packages (from docker) (2.32.4)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\soheil\\appdata\\local\\pypoetry\\cache\\virtualenvs\\emotion-clf-pipeline-boncazar-py3.11\\lib\\site-packages (from docker) (2.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\soheil\\appdata\\local\\pypoetry\\cache\\virtualenvs\\emotion-clf-pipeline-boncazar-py3.11\\lib\\site-packages (from requests>=2.26.0->docker) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soheil\\appdata\\local\\pypoetry\\cache\\virtualenvs\\emotion-clf-pipeline-boncazar-py3.11\\lib\\site-packages (from requests>=2.26.0->docker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soheil\\appdata\\local\\pypoetry\\cache\\virtualenvs\\emotion-clf-pipeline-boncazar-py3.11\\lib\\site-packages (from requests>=2.26.0->docker) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "# Install docker package in the current Jupyter kernel\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a local endpoint, using the `local` deployment target. This will create a local endpoint that will run on your machine using Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local endpoint (local-06201921868040) .Done (0m 5s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': None, 'provisioning_state': None, 'scoring_uri': None, 'openapi_uri': None, 'name': 'local-06201921868040', 'description': 'this is a sample local endpoint', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': WindowsPath('C:/Users/Soheil/.azureml/inferencing/local-06201921868040'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000018C4CA57610>, 'auth_mode': 'key', 'location': None, 'identity': None, 'traffic': {}, 'mirror_traffic': {}, 'kind': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint, local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now create the deployment config for the local endpoint. This will be used to create a service that will expose the model as an endpoint. You need to specfiy the model, the environment, the scoring script, and the endpoint configuration. The model needs to be a local model for this to work locally.\n",
    "\n",
    "**_Note: The environment and the scoring script are the main sources of error at this stage. You will need to make sure the environment has all the pre-requisites and that all of your path definitions for scoring are correct. Extensive logging is recommended for debugging._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baseline_weights.pt', 'current_run_temp_weights', 'emotion-clf-dynamic', 'model_config.json', 'sync_status.json']\n",
      "x:\\University\\2024-25d-fai2-adsai-group-nlp6\n",
      "['api.py', 'azure_endpoint.py', 'azure_pipeline.py', 'azure_score.py', 'azure_sync.py', 'cli.py', 'data.py', 'features.py', 'hyperparameter_tuning.py', 'model.py', 'predict.py', 'stt.py', 'train.py', 'transcript.py', 'transcript_translator.py', 'translator.py', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "import os\n",
    "\n",
    "print(os.listdir('./models/weights/'))\n",
    "model = Model(\n",
    "    # path=\"../models/download/model.keraenv\n",
    "    path = \"./models/weights/baseline_weights.pt\"\n",
    ")\n",
    "env = Environment(\n",
    "    conda_file=\"./environment/environment.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\"  #\"deanis/azure-gpu-inference\"#\"tensorflow/tensorflow:latest-gpu\"#\"mcr.microsoft.com/azureml/curated/tensorflow-2.16-cuda11:4\"#\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    ")\n",
    "\n",
    "print(os.getcwd())\n",
    "print(os.listdir('./src/emotion_clf_pipeline'))\n",
    "\n",
    "blue_deployment = KubernetesOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=local_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./src/emotion_clf_pipeline\", \n",
    "        scoring_script=\"scoring.py\"\n",
    "    ),\n",
    "    instance_count=1,\n",
    "    resources=ResourceRequirementsSettings(\n",
    "        requests=ResourceSettings(\n",
    "            cpu=\"100m\",\n",
    "            memory=\"0.5Gi\",\n",
    "            gpu=\"1\",\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, deploy the model as an endpoint, using the `local` flag. This will deploy the model to the local endpoint that was created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker daemon is running\n",
      "Docker version: {'Platform': {'Name': 'Docker Desktop 4.42.1 (196648)'}, 'Components': [{'Name': 'Engine', 'Version': '28.2.2', 'Details': {'ApiVersion': '1.50', 'Arch': 'amd64', 'BuildTime': '2025-05-30T12:07:26.000000000+00:00', 'Experimental': 'false', 'GitCommit': '45873be', 'GoVersion': 'go1.24.3', 'KernelVersion': '6.6.87.1-microsoft-standard-WSL2', 'MinAPIVersion': '1.24', 'Os': 'linux'}}, {'Name': 'containerd', 'Version': '1.7.27', 'Details': {'GitCommit': '05044ec0a9a75232cad458027ca83437aae3f4da'}}, {'Name': 'runc', 'Version': '1.2.5', 'Details': {'GitCommit': 'v1.2.5-0-g59923ef'}}, {'Name': 'docker-init', 'Version': '0.19.0', 'Details': {'GitCommit': 'de40ad0'}}], 'Version': '28.2.2', 'ApiVersion': '1.50', 'MinAPIVersion': '1.24', 'GitCommit': '45873be', 'GoVersion': 'go1.24.3', 'Os': 'linux', 'Arch': 'amd64', 'KernelVersion': '6.6.87.1-microsoft-standard-WSL2', 'BuildTime': '2025-05-30T12:07:26.000000000+00:00'}\n",
      "MCR connectivity issue: <urlopen error [WinError 10054] An existing connection was forcibly closed by the remote host>\n",
      "✓ Scoring script found: ./src/emotion_clf_pipeline/azure_score.py\n"
     ]
    }
   ],
   "source": [
    "# Pre-deployment troubleshooting\n",
    "import docker\n",
    "\n",
    "# Check Docker daemon status\n",
    "try:\n",
    "    client = docker.from_env()\n",
    "    print(\"Docker daemon is running\")\n",
    "    print(\"Docker version:\", client.version())\n",
    "except Exception as e:\n",
    "    print(f\"Docker issue: {e}\")\n",
    "\n",
    "# Test network connectivity to MCR\n",
    "import urllib.request\n",
    "try:\n",
    "    response = urllib.request.urlopen('https://mcr.microsoft.com', timeout=10)\n",
    "    print(\"MCR connectivity: OK\")\n",
    "except Exception as e:\n",
    "    print(f\"MCR connectivity issue: {e}\")\n",
    "\n",
    "# Verify scoring script exists\n",
    "scoring_script_path = \"./src/emotion_clf_pipeline/azure_score.py\"\n",
    "if os.path.exists(scoring_script_path):\n",
    "    print(f\"✓ Scoring script found: {scoring_script_path}\")\n",
    "else:\n",
    "    print(f\"✗ Scoring script missing: {scoring_script_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local deployment (local-06201921868040 / blue) .\n",
      "Building Docker image from Dockerfile"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/6 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\n",
      "failed to resolve reference \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\": failed to do request: Head \"https://mcr.microsoft.com/v2/azureml/openmpi4.1.0-ubuntu20.04/manifests/latest\": EOFDone (0m 5s)\n"
     ]
    },
    {
     "ename": "LocalEndpointImageBuildError",
     "evalue": "Building the local endpoint image failed with error: failed to resolve reference \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\": failed to do request: Head \"https://mcr.microsoft.com/v2/azureml/openmpi4.1.0-ubuntu20.04/manifests/latest\": EOF",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLocalEndpointImageBuildError\u001b[39m              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mml_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43monline_deployments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblue_deployment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:138\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes.items():\n\u001b[32m    137\u001b[39m                 span.add_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[32m    141\u001b[39m     config = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\_telemetry\\activity.py:288\u001b[39m, in \u001b[36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracer.start_as_current_span(ACTIVITY_SPAN):\n\u001b[32m    285\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[32m    286\u001b[39m             logger.package_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f.\u001b[34m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[32m    287\u001b[39m         ):\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[33m\"\u001b[39m\u001b[33mpackage_logger\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger.package_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f.\u001b[34m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\operations\\_online_deployment_operations.py:218\u001b[39m, in \u001b[36mOnlineDeploymentOperations.begin_create_or_update\u001b[39m\u001b[34m(self, deployment, local, vscode_debug, skip_script_validation, local_enable_gpu, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m     log_and_raise_error(ex)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\operations\\_online_deployment_operations.py:144\u001b[39m, in \u001b[36mOnlineDeploymentOperations.begin_create_or_update\u001b[39m\u001b[34m(self, deployment, local, vscode_debug, skip_script_validation, local_enable_gpu, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m    138\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m LocalDeploymentGPUNotAvailable(\n\u001b[32m    139\u001b[39m                 msg=(\n\u001b[32m    140\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mNvidia GPU is not available in your local system.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    141\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33m Use nvidia-smi command to see the available GPU\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    142\u001b[39m                 )\n\u001b[32m    143\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_local_deployment_helper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_local_endpoint_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvscode_debug\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deployment \u001b[38;5;129;01mand\u001b[39;00m deployment.instance_type \u001b[38;5;129;01mand\u001b[39;00m deployment.instance_type.lower() \u001b[38;5;129;01min\u001b[39;00m SmallSKUs:\n\u001b[32m    150\u001b[39m     module_logger.warning(\n\u001b[32m    151\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInstance type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m may be too small for compute resources. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    152\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMinimum recommended compute SKU is Standard_DS3_v2 for general purpose endpoints. Learn more about SKUs here: \u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[32m    153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://learn.microsoft.com/azure/machine-learning/referencemanaged-online-endpoints-vm-sku-list\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    154\u001b[39m         deployment.instance_type,\n\u001b[32m    155\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\operations\\_local_deployment_helper.py:105\u001b[39m, in \u001b[36m_LocalDeploymentHelper.create_or_update\u001b[39m\u001b[34m(self, deployment, local_endpoint_mode, local_enable_gpu)\u001b[39m\n\u001b[32m    103\u001b[39m     log_and_raise_error(ex)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\operations\\_local_deployment_helper.py:90\u001b[39m, in \u001b[36m_LocalDeploymentHelper.create_or_update\u001b[39m\u001b[34m(self, deployment, local_endpoint_mode, local_enable_gpu)\u001b[39m\n\u001b[32m     84\u001b[39m     deployment_metadata = json.dumps(deployment._to_dict())\n\u001b[32m     85\u001b[39m     endpoint_metadata = (\n\u001b[32m     86\u001b[39m         endpoint_metadata\n\u001b[32m     87\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m endpoint_metadata\n\u001b[32m     88\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m _get_stubbed_endpoint_metadata(endpoint_name=\u001b[38;5;28mstr\u001b[39m(deployment.endpoint_name))\n\u001b[32m     89\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[43mlocal_endpoint_polling_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_deployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moperation_message\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdeployment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m / \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdeployment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m) \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeployment_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeployment_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get(endpoint_name=\u001b[38;5;28mstr\u001b[39m(deployment.endpoint_name), deployment_name=\u001b[38;5;28mstr\u001b[39m(deployment.name))\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:  \u001b[38;5;66;03m# pylint: disable=W0718\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\_utils\\_endpoint_utils.py:103\u001b[39m, in \u001b[36mlocal_endpoint_polling_wrapper\u001b[39m\u001b[34m(func, message, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m event = pool.submit(func, **kwargs)\n\u001b[32m    102\u001b[39m polling_wait(poller=event, start_time=start_time, message=message, is_local=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\operations\\_local_deployment_helper.py:300\u001b[39m, in \u001b[36m_LocalDeploymentHelper._create_deployment\u001b[39m\u001b[34m(self, endpoint_name, deployment, local_endpoint_mode, local_enable_gpu, endpoint_metadata, deployment_metadata)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;66;03m# Determine whether we need to use local context or downloaded context\u001b[39;00m\n\u001b[32m    299\u001b[39m build_directory = downloaded_build_context \u001b[38;5;28;01mif\u001b[39;00m downloaded_build_context \u001b[38;5;28;01melse\u001b[39;00m deployment_directory\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_docker_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_deployment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeployment_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeployment_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdockerfile_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_byoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdockerfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconda_source_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43myaml_env_conda_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconda_yaml_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43myaml_env_conda_file_contents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvolumes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvolumes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mazureml_port\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscoring_route\u001b[49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_byoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mLocalEndpointConstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOCKER_PORT\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_endpoint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprebuilt_image_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43myaml_base_image_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_byoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_enable_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\_local_endpoints\\docker_client.py:154\u001b[39m, in \u001b[36mDockerClient.create_deployment\u001b[39m\u001b[34m(self, endpoint_name, deployment_name, endpoint_metadata, deployment_metadata, build_directory, dockerfile_path, conda_source_path, conda_yaml_contents, volumes, environment, azureml_port, local_endpoint_mode, prebuilt_image_name, local_enable_gpu)\u001b[39m\n\u001b[32m    152\u001b[39m     module_logger.debug(\u001b[33m\"\u001b[39m\u001b[33mDockerfile path: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, dockerfile_path)\n\u001b[32m    153\u001b[39m     module_logger.debug(\u001b[33m\"\u001b[39m\u001b[33mImage \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is built.\u001b[39m\u001b[33m\"\u001b[39m, image_name)\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdockerfile_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdockerfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_source_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_source_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_yaml_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_yaml_contents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    162\u001b[39m     image_name = prebuilt_image_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Soheil\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\emotion-clf-pipeline-bOnCAZAr-py3.11\\Lib\\site-packages\\azure\\ai\\ml\\_local_endpoints\\docker_client.py:418\u001b[39m, in \u001b[36mDockerClient._build_image\u001b[39m\u001b[34m(self, build_directory, image_name, dockerfile_path, conda_source_path, conda_yaml_contents)\u001b[39m\n\u001b[32m    416\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m status:\n\u001b[32m    417\u001b[39m             module_logger.info(status[\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m LocalEndpointImageBuildError(status[\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m docker.errors.APIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEndpointImageBuildError(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mLocalEndpointImageBuildError\u001b[39m: Building the local endpoint image failed with error: failed to resolve reference \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\": failed to do request: Head \"https://mcr.microsoft.com/v2/azureml/openmpi4.1.0-ubuntu20.04/manifests/latest\": EOF"
     ]
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(\n",
    "    deployment=blue_deployment, local=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating local deployment (local-06190730925377 / blue) .\n",
      "Building Docker image from Dockerfile\n",
      "Step 1/6 : FROM mcr.microsoft.com/azureml/curated/tensorflow-2.16-cuda11:4\n",
      " ---> 6d0ec349c317\n",
      "Step 2/6 : RUN mkdir -p /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> a6fb8a24a661\n",
      "Step 3/6 : WORKDIR /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> 351579f60e7e\n",
      "Step 4/6 : COPY conda.yml /var/azureml-app/\n",
      " ---> Using cache\n",
      " ---> ea5d11993718\n",
      "Step 5/6 : RUN conda env create -n inf-conda-env --file conda.yml\n",
      " ---> Using cache\n",
      " ---> be1157b1d1bc\n",
      "Step 6/6 : CMD [\"conda\", \"run\", \"--no-capture-output\", \"-n\", \"inf-conda-env\", \"runsvdir\", \"/var/runit\"]\n",
      " ---> Using cache\n",
      " ---> f80d2ed2858f\n",
      "Successfully built f80d2ed2858f\n",
      "Successfully tagged local-06190730925377:blue\n",
      "\n",
      "Starting up endpoint...Done (0m 20s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KubernetesOnlineDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'local-06190730925377', 'type': 'Kubernetes', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': WindowsPath('c:/Users/deanv/Dropbox/0_Buas/2023-2024/y2D/Azure Content Testing/Example-App-master/Example-App-master/Notebooks'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001A8E7579BA0>, 'model': Model({'job_name': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': '6cb2a977a20c09f3db4caf0af16a5008', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': WindowsPath('c:/Users/deanv/Dropbox/0_Buas/2023-2024/y2D/Azure Content Testing/Example-App-master/Example-App-master/Notebooks'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001A8E757BC10>, 'version': '1', 'latest_version': None, 'path': 'C:\\\\Users\\\\deanv\\\\Dropbox\\\\0_Buas\\\\2023-2024\\\\y2D\\\\Azure Content Testing\\\\Example-App-master\\\\Example-App-master\\\\models\\\\download\\\\model.keras', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model', 'stage': None}), 'code_configuration': {'code': '../src/number_predictor'}, 'environment': Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': 'mcr.microsoft.com/azureml/curated/tensorflow-2.16-cuda11:4', 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'CliV2AnonymousEnvironment', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': '', 'base_path': WindowsPath('c:/Users/deanv/Dropbox/0_Buas/2023-2024/y2D/Azure Content Testing/Example-App-master/Example-App-master/Notebooks'), 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001A8E757BF40>, 'version': '1304d44e0b82dabb33fddbf355d93cee', 'conda_file': {'name': 'example_conda', 'channels': ['defaults'], 'dependencies': ['python=3.11', 'numpy', 'pandas', 'pip', {'pip': ['pillow', 'fastapi', 'uvicorn', 'azureml', 'azure-core', 'azure-identity', 'azureml-core', 'azure-ai-ml', 'mlflow', 'azureml-inference-server-http', 'azureml-defaults', 'azureml-mlflow', 'tensorflow']}]}, 'build': None, 'inference_config': None, 'os_type': None, 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': 'channels:\\n- defaults\\ndependencies:\\n- python=3.11\\n- numpy\\n- pandas\\n- pip\\n- pip:\\n  - pillow\\n  - fastapi\\n  - uvicorn\\n  - azureml\\n  - azure-core\\n  - azure-identity\\n  - azureml-core\\n  - azure-ai-ml\\n  - mlflow\\n  - azureml-inference-server-http\\n  - azureml-defaults\\n  - azureml-mlflow\\n  - tensorflow\\nname: example_conda\\n'}), 'environment_variables': {}, 'app_insights_enabled': False, 'scale_settings': None, 'request_settings': None, 'liveness_probe': None, 'readiness_probe': None, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'local', 'data_collector': None, 'resources': <azure.ai.ml.entities._deployment.resource_requirements_settings.ResourceRequirementsSettings object at 0x000001A8E757BC40>})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(\n",
    "    deployment=blue_deployment, local=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can check the status of the deployment by looking at the logs of the docker container that was created. In docker desktop, you can do this by clicking on the container, and then clicking on the logs tab. The container will be named something like `local-06160804621045.blue`.\n",
    "\n",
    "- You can also check the status of the deployment by looking at the logs of the deployment with the `ml_client`. You can do this by calling the `get_logs` method on the deployment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth_mode: key\n",
      "description: this is a sample local endpoint\n",
      "location: local\n",
      "mirror_traffic: {}\n",
      "name: local-06190730925377\n",
      "properties: {}\n",
      "provisioning_state: Succeeded\n",
      "scoring_uri: http://localhost:32776/score\n",
      "tags: {}\n",
      "traffic: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status = ml_client.online_endpoints.get(name=local_endpoint_name, local=True)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========\n",
      "== CUDA ==\n",
      "==========\n",
      "\n",
      "CUDA Version 11.8.0\n",
      "\n",
      "Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.\n",
      "\n",
      "WARNING: The NVIDIA Driver was not detected.  GPU functionality will not be available.\n",
      "   Use the NVIDIA Container Toolkit to start this container with GPU support; see\n",
      "   https://docs.nvidia.com/datacenter/cloud-native/ .\n",
      "\n",
      "2024-06-19T05:30:37,166462030+00:00 - rsyslog/run \n",
      "2024-06-19T05:30:37,178807446+00:00 - gunicorn/run \n",
      "2024-06-19T05:30:37,183517686+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:37,184568390+00:00 - nginx/run \n",
      "2024-06-19T05:30:37,187054749+00:00 | gunicorn/run | ###############################################\n",
      "2024-06-19T05:30:37,189716981+00:00 | gunicorn/run | AzureML Container Runtime Information\n",
      "2024-06-19T05:30:37,191655386+00:00 | gunicorn/run | ###############################################\n",
      "2024-06-19T05:30:37,193924974+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:37,531102767+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:37,534464998+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04, Materializaton Build:20240603.v1\n",
      "2024-06-19T05:30:37,536891190+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:37,538644410+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:37,540180891+00:00 | gunicorn/run | PATH environment variable: /opt/miniconda/envs/inf-conda-env/bin:/opt/miniconda/condabin:/azureml-envs/tensorflow-2.16-cuda11/bin:/opt/miniconda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "2024-06-19T05:30:37,541384444+00:00 | gunicorn/run | PYTHONPATH environment variable: \n",
      "2024-06-19T05:30:37,543122094+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:37,842870429+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n",
      "\n",
      "# conda environments:\n",
      "#\n",
      "                         /azureml-envs/tensorflow-2.16-cuda11\n",
      "base                     /opt/miniconda\n",
      "inf-conda-env         *  /opt/miniconda/envs/inf-conda-env\n",
      "\n",
      "2024-06-19T05:30:38,353642328+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:38,354590207+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n",
      "\n",
      "absl-py==2.1.0\n",
      "adal==1.2.7\n",
      "alembic==1.13.1\n",
      "aniso8601==9.0.1\n",
      "annotated-types==0.7.0\n",
      "anyio==4.4.0\n",
      "argcomplete==3.4.0\n",
      "astunparse==1.6.3\n",
      "attrs==23.2.0\n",
      "azure-ai-ml==1.16.1\n",
      "azure-common==1.1.28\n",
      "azure-core==1.30.2\n",
      "azure-graphrbac==0.61.1\n",
      "azure-identity==1.16.1\n",
      "azure-mgmt-authorization==4.0.0\n",
      "azure-mgmt-containerregistry==10.3.0\n",
      "azure-mgmt-core==1.4.0\n",
      "azure-mgmt-keyvault==10.3.0\n",
      "azure-mgmt-network==25.4.0\n",
      "azure-mgmt-resource==23.1.1\n",
      "azure-mgmt-storage==21.1.0\n",
      "azure-storage-blob==12.19.0\n",
      "azure-storage-file-datalake==12.14.0\n",
      "azure-storage-file-share==12.16.0\n",
      "azureml==0.2.7\n",
      "azureml-core==1.56.0\n",
      "azureml-dataprep==5.1.6\n",
      "azureml-dataprep-native==41.0.0\n",
      "azureml-dataprep-rslex==2.22.2\n",
      "azureml-dataset-runtime==1.56.0\n",
      "azureml-defaults==1.56.0.post1\n",
      "azureml-inference-server-http==1.2.2\n",
      "azureml-mlflow==1.56.0\n",
      "backports.tempfile==1.0\n",
      "backports.weakref==1.0.post1\n",
      "bcrypt==4.1.3\n",
      "blinker==1.8.2\n",
      "Bottleneck @ file:///croot/bottleneck_1707864210935/work\n",
      "cachetools==5.3.3\n",
      "certifi==2024.6.2\n",
      "cffi==1.16.0\n",
      "charset-normalizer==3.3.2\n",
      "click==8.1.7\n",
      "cloudpickle==2.2.1\n",
      "colorama==0.4.6\n",
      "contextlib2==21.6.0\n",
      "contourpy==1.2.1\n",
      "cryptography==42.0.8\n",
      "cycler==0.12.1\n",
      "Deprecated==1.2.14\n",
      "dnspython==2.6.1\n",
      "docker==7.1.0\n",
      "email_validator==2.1.1\n",
      "entrypoints==0.4\n",
      "fastapi==0.111.0\n",
      "fastapi-cli==0.0.4\n",
      "Flask==2.3.2\n",
      "Flask-Cors==3.0.10\n",
      "flatbuffers==24.3.25\n",
      "fonttools==4.53.0\n",
      "fusepy==3.0.1\n",
      "gast==0.5.4\n",
      "gitdb==4.0.11\n",
      "GitPython==3.1.43\n",
      "google-api-core==2.19.0\n",
      "google-auth==2.30.0\n",
      "google-pasta==0.2.0\n",
      "googleapis-common-protos==1.63.1\n",
      "graphene==3.3\n",
      "graphql-core==3.2.3\n",
      "graphql-relay==3.2.0\n",
      "greenlet==3.0.3\n",
      "grpcio==1.64.1\n",
      "gunicorn==22.0.0\n",
      "h11==0.14.0\n",
      "h5py==3.11.0\n",
      "httpcore==1.0.5\n",
      "httptools==0.6.1\n",
      "httpx==0.27.0\n",
      "humanfriendly==10.0\n",
      "idna==3.7\n",
      "importlib_metadata==7.1.0\n",
      "inference-schema==1.7.2\n",
      "isodate==0.6.1\n",
      "itsdangerous==2.2.0\n",
      "jeepney==0.8.0\n",
      "Jinja2==3.1.4\n",
      "jmespath==1.0.1\n",
      "joblib==1.4.2\n",
      "jsonpickle==3.2.1\n",
      "jsonschema==4.22.0\n",
      "jsonschema-specifications==2023.12.1\n",
      "keras==3.3.3\n",
      "kiwisolver==1.4.5\n",
      "knack==0.11.0\n",
      "libclang==18.1.1\n",
      "Mako==1.3.5\n",
      "Markdown==3.6\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==2.1.5\n",
      "marshmallow==3.21.3\n",
      "matplotlib==3.9.0\n",
      "mdurl==0.1.2\n",
      "mkl-fft @ file:///croot/mkl_fft_1695058164594/work\n",
      "mkl-random @ file:///croot/mkl_random_1695059800811/work\n",
      "mkl-service==2.4.0\n",
      "ml-dtypes==0.3.2\n",
      "mlflow==2.13.2\n",
      "mlflow-skinny==2.13.2\n",
      "msal==1.28.1\n",
      "msal-extensions==1.1.0\n",
      "msrest==0.7.1\n",
      "msrestazure==0.6.4\n",
      "namex==0.0.8\n",
      "ndg-httpsclient==0.5.1\n",
      "numexpr @ file:///croot/numexpr_1696515281613/work\n",
      "numpy==1.23.5\n",
      "oauthlib==3.2.2\n",
      "opencensus==0.11.4\n",
      "opencensus-context==0.1.3\n",
      "opencensus-ext-azure==1.1.13\n",
      "opencensus-ext-logging==0.1.1\n",
      "opentelemetry-api==1.25.0\n",
      "opentelemetry-sdk==1.25.0\n",
      "opentelemetry-semantic-conventions==0.46b0\n",
      "opt-einsum==3.3.0\n",
      "optree==0.11.0\n",
      "orjson==3.10.5\n",
      "packaging==24.1\n",
      "pandas @ file:///croot/pandas_1718308974269/work/dist/pandas-2.2.2-cp311-cp311-linux_x86_64.whl#sha256=3c7ce50f9f519c785bd4cdb28a0ca71f85a541f3d27b25aa9da770f953e7f2e9\n",
      "paramiko==3.4.0\n",
      "pathspec==0.12.1\n",
      "pillow==10.3.0\n",
      "pkginfo==1.11.1\n",
      "portalocker==2.8.2\n",
      "proto-plus==1.23.0\n",
      "protobuf==4.25.3\n",
      "psutil==5.9.8\n",
      "pyarrow==15.0.2\n",
      "pyasn1==0.6.0\n",
      "pyasn1_modules==0.4.0\n",
      "pycparser==2.22\n",
      "pydantic==2.7.4\n",
      "pydantic-settings==2.3.3\n",
      "pydantic_core==2.18.4\n",
      "pydash==8.0.1\n",
      "Pygments==2.18.0\n",
      "PyJWT==2.8.0\n",
      "PyNaCl==1.5.0\n",
      "pyOpenSSL==24.1.0\n",
      "pyparsing==3.1.2\n",
      "PySocks==1.7.1\n",
      "python-dateutil @ file:///croot/python-dateutil_1716495738603/work\n",
      "python-dotenv==1.0.1\n",
      "python-multipart==0.0.9\n",
      "pytz @ file:///croot/pytz_1713974312559/work\n",
      "PyYAML==6.0.1\n",
      "querystring-parser==1.2.4\n",
      "referencing==0.35.1\n",
      "requests==2.32.3\n",
      "requests-oauthlib==2.0.0\n",
      "rich==13.7.1\n",
      "rpds-py==0.18.1\n",
      "rsa==4.9\n",
      "scikit-learn==1.5.0\n",
      "scipy==1.13.1\n",
      "SecretStorage==3.3.3\n",
      "shellingham==1.5.4\n",
      "six @ file:///tmp/build/80754af9/six_1644875935023/work\n",
      "smmap==5.0.1\n",
      "sniffio==1.3.1\n",
      "SQLAlchemy==2.0.30\n",
      "sqlparse==0.5.0\n",
      "starlette==0.37.2\n",
      "strictyaml==1.7.3\n",
      "tabulate==0.9.0\n",
      "tensorboard==2.16.2\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.16.1\n",
      "tensorflow-io-gcs-filesystem==0.37.0\n",
      "termcolor==2.4.0\n",
      "threadpoolctl==3.5.0\n",
      "tqdm==4.66.4\n",
      "typer==0.12.3\n",
      "typing_extensions==4.12.2\n",
      "tzdata @ file:///croot/python-tzdata_1690578112552/work\n",
      "ujson==5.10.0\n",
      "urllib3==2.2.1\n",
      "uvicorn==0.30.1\n",
      "uvloop==0.19.0\n",
      "watchfiles==0.22.0\n",
      "websockets==12.0\n",
      "Werkzeug==3.0.3\n",
      "wrapt==1.16.0\n",
      "zipp==3.19.2\n",
      "\n",
      "2024-06-19T05:30:39,853655342+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:39,855158322+00:00 | gunicorn/run | Entry script directory: /var/azureml-app/number_predictor//.\n",
      "2024-06-19T05:30:39,856379297+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:39,857462974+00:00 | gunicorn/run | ###############################################\n",
      "2024-06-19T05:30:39,858555637+00:00 | gunicorn/run | Dynamic Python Package Installation\n",
      "2024-06-19T05:30:39,859861141+00:00 | gunicorn/run | ###############################################\n",
      "2024-06-19T05:30:39,860717697+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:39,861626725+00:00 | gunicorn/run | Dynamic Python package installation is disabled.\n",
      "2024-06-19T05:30:39,862507340+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:39,863391268+00:00 | gunicorn/run | ###############################################\n",
      "2024-06-19T05:30:39,864438452+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n",
      "2024-06-19T05:30:39,865461497+00:00 | gunicorn/run | ###############################################\n",
      "2024-06-19T05:30:39,866364899+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:41,024993827+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:41,026618617+00:00 | gunicorn/run | ###############################################\n",
      "2024-06-19T05:30:41,028213949+00:00 | gunicorn/run | AzureML Inference Server\n",
      "2024-06-19T05:30:41,030283318+00:00 | gunicorn/run | ###############################################\n",
      "2024-06-19T05:30:41,031138415+00:00 | gunicorn/run | \n",
      "2024-06-19T05:30:41,034121494+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n",
      "2024-06-19 05:30:41,203 I [50] azmlinfsrv - Loaded logging config from /opt/miniconda/envs/inf-conda-env/lib/python3.11/site-packages/azureml_inference_server_http/logging.json\n",
      "\n",
      "Azure ML Inferencing HTTP server v1.2.2\n",
      "\n",
      "\n",
      "Server Settings\n",
      "---------------\n",
      "Entry Script Name: /var/azureml-app/number_predictor/scoring.py\n",
      "Model Directory: /var/azureml-app/azureml-models//6cb2a977a20c09f3db4caf0af16a5008/1\n",
      "Config File: None\n",
      "Worker Count: 1\n",
      "Worker Timeout (seconds): 300\n",
      "Server Port: 31311\n",
      "Health Port: 31311\n",
      "Application Insights Enabled: false\n",
      "Application Insights Key: None\n",
      "Inferencing HTTP server version: azmlinfsrv/1.2.2\n",
      "CORS for the specified origins: None\n",
      "Create dedicated endpoint for health: None\n",
      "\n",
      "\n",
      "Server Routes\n",
      "---------------\n",
      "Liveness Probe: GET   127.0.0.1:31311/\n",
      "Score:          POST  127.0.0.1:31311/score\n",
      "\n",
      "\n",
      "Warnings\n",
      "---------------\n",
      "Azmlinfsrv will be migrating to Pydantic 2.0 on 1/15/24. This is a breaking change for any Pydantic 1.0 code.\n",
      "\n",
      "2024-06-19 05:30:41,242 I [50] gunicorn.error - Starting gunicorn 22.0.0\n",
      "2024-06-19 05:30:41,244 I [50] gunicorn.error - Listening at: http://0.0.0.0:31311 (50)\n",
      "2024-06-19 05:30:41,244 I [50] gunicorn.error - Using worker: sync\n",
      "2024-06-19 05:30:41,248 I [130] gunicorn.error - Booting worker with pid: 130\n",
      "/opt/miniconda/envs/inf-conda-env/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_dc_storage_enabled\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
      "  warnings.warn(\n",
      "2024-06-19 05:30:41,464 W [130] azmlinfsrv - Found extra keys in the config file that are not supported by the server.\n",
      "Extra keys = ['AZUREML_ENTRY_SCRIPT', 'AZUREML_MODEL_DIR', 'HOSTNAME']\n",
      "2024-06-19 05:30:42,176 I [130] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\n",
      "Initializing logger\n",
      "2024-06-19 05:30:42,184 I [130] azmlinfsrv - Starting up app insights client\n",
      "2024-06-19 05:30:44.387067: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-19 05:30:44.397118: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-19 05:30:44.651441: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-19 05:30:45.743623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-19 05:30:47.573236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-19 05:30:50,536 I [130] azmlinfsrv.user_script - Found user script at /var/azureml-app/number_predictor/scoring.py\n",
      "2024-06-19 05:30:50,536 I [130] azmlinfsrv.user_script - run() is not decorated. Server will invoke it with the input in JSON string.\n",
      "2024-06-19 05:30:50,536 I [130] azmlinfsrv.user_script - Invoking user's init function\n",
      "WARNING:tensorflow:From /var/azureml-app/number_predictor/scoring.py:15: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "2024-06-19 05:30:50,566 I [130] azmlinfsrv.print - The CPU will be used for scoring.\n",
      "2024-06-19 05:30:50,568 I [130] azmlinfsrv.print - Gpus: []\n",
      "2024-06-19 05:30:50,568 I [130] azmlinfsrv.print - No GPU found :(\n",
      "2024-06-19 05:30:50,568 I [130] azmlinfsrv.print - Could not set memory growth for GPU\n",
      "2024-06-19 05:30:50,568 I [130] azmlinfsrv.print - base_path: /var/azureml-app/azureml-models//6cb2a977a20c09f3db4caf0af16a5008/1\n",
      "2024-06-19 05:30:50,568 I [130] azmlinfsrv.print - list files in the model_path directory\n",
      "2024-06-19 05:30:50,571 I [130] azmlinfsrv.print - 1/\n",
      "2024-06-19 05:30:50,572 I [130] azmlinfsrv.print -     model.keras\n",
      "2024-06-19 05:30:50,572 I [130] azmlinfsrv.print - model_path: /var/azureml-app/azureml-models//6cb2a977a20c09f3db4caf0af16a5008/1/model.keras\n",
      "2024-06-19 05:30:51,142 I [130] azmlinfsrv.print - Model loaded successfully\n",
      "2024-06-19 05:30:51,142 I [130] azmlinfsrv.user_script - Users's init has completed successfully\n",
      "2024-06-19 05:30:51,144 I [130] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n",
      "2024-06-19 05:30:51,144 I [130] azmlinfsrv - Scoring timeout is set to 3600000\n",
      "2024-06-19 05:30:51,144 I [130] azmlinfsrv - Worker with pid 130 ready for serving traffic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs = ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=local_endpoint_name, local=True, lines=500\n",
    ")\n",
    "\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing 🧪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the deployment is successful, you can test the endpoint by sending data to it. We will do this by sending a request to the endpoint using the `invoke` method on the deployment object. This will send a request to the endpoint, and return the response. The format of the request and response will depend on the scoring script that was used to create the endpoint. In this case the scoring script is `scoring.py`, which expects a JSON object with a key `data` that contains the data to be scored. The data is a base64 encoded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"4\"'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=local_endpoint_name,\n",
    "    request_file=\"sample-request4.json\",\n",
    "    local=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud Deployment 🌐\n",
    "\n",
    "Once the local deployment is successful, we can deploy the model to the cloud. This is useful for serving the model to a large number of users, and for making the model accessible from anywhere. It is also useful for deploying the model to a production environment.\n",
    "\n",
    "- First we need to create the endpoint configuration for the cloud deployment. This will define thename, authorisation method, and compute resources that will be used to serve the endpoint. We will use the `KubernetesOnlineEndpoint` class to deploy the model to the already running K8s cluster. This class will create a service that will expose the model as an endpoint. We use this instead of the `ManagedOnlineEndpoint` class because the `ManagedOnlineEndpoint` class will create Azure compute instances to serve the endpoint, which is more expensive and less performant than using the already running K8s cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"k8s-endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = KubernetesOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    compute=\"adsai1\",\n",
    "    description=\"this is a sample online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"Type\": \"Review Session\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KubernetesOnlineEndpoint({'provisioning_state': 'Succeeded', 'scoring_uri': 'http://194.171.191.227:30397/api/v1/endpoint/k8s-endpoint-06190829258926/score', 'openapi_uri': 'http://194.171.191.227:30397/api/v1/endpoint/k8s-endpoint-06190829258926/swagger.json', 'name': 'k8s-endpoint-06190829258926', 'description': 'this is a sample online endpoint', 'tags': {'Type': 'Review Session'}, 'properties': {'createdBy': 'a2230f31-0fda-428d-8c5c-ec79e91a49f5', 'createdAt': '2024-06-19T06:29:52.864258+0000', 'lastModifiedAt': '2024-06-19T06:29:52.864258+0000', 'azureml.onlineendpointid': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourcegroups/buas-y2/providers/microsoft.machinelearningservices/workspaces/staff-test/onlineendpoints/k8s-endpoint-06190829258926', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/providers/Microsoft.MachineLearningServices/locations/westeurope/mfeOperationsStatus/oeidp:798f953a-277e-4ed7-90e2-0e1cd6d888eb:c708e594-15b0-47d3-82c2-04dc6f7e8e2f?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/onlineEndpoints/k8s-endpoint-06190829258926', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\deanv\\\\Dropbox\\\\0_Buas\\\\2023-2024\\\\y2D\\\\Azure Content Testing\\\\Example-App-master\\\\Example-App-master\\\\Notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001A8E75EECE0>, 'auth_mode': 'key', 'location': 'westeurope', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x000001A8E76C3910>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'K8S', 'compute': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/computes/adsai1'})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next we need to create the deployment config for the cloud deployment. This will be used to create a service that will expose the model as an endpoint. You need to specfiy the model, the environment, the scoring script, and the endpoint configuration. We can now use registered models (and environments) for this deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deanv\\Dropbox\\0_Buas\\2023-2024\\y2D\\Azure Content Testing\\Example-App-master\\Example-App-master\\Notebooks\n",
      "['app.py', 'azure_utils', 'evaluate.py', 'load_data.py', 'model.py', 'models', 'predict.py', 'register.py', 'scoring.py', 'train.py', '__init__.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "import os\n",
    "\n",
    "env = Environment(\n",
    "    # conda_file=\"../../../example_conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/curated/tensorflow-2.16-cuda11:4\"#\"deanis/azure-gpu-inference\"#\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    ")\n",
    "\n",
    "registered_model_name = \"example_2\"\n",
    "latest_model_version = 2\n",
    "registered_environment_name = \"endpoint_env_inference\"\n",
    "latest_environment_version = 2\n",
    "\n",
    "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
    "# env = ml_client.environments.get(name=registered_environment_name, version=latest_environment_version)\n",
    "\n",
    "print(os.getcwd())\n",
    "print(os.listdir('../src/number_predictor'))\n",
    "\n",
    "blue_deployment = KubernetesOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../src/number_predictor\", scoring_script=\"scoring.py\"\n",
    "    ),\n",
    "    instance_count=1,\n",
    "    resources=ResourceRequirementsSettings(\n",
    "        requests=ResourceSettings(\n",
    "            cpu=\"100m\",\n",
    "            memory=\"0.5Gi\",\n",
    "        ),\n",
    "        # limits=ResourceSettings(\n",
    "        #     cpu=\"1\",\n",
    "        #     memory=\"2Gi\",\n",
    "        #     gpu=1,\n",
    "        # ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can now deploy the model as an endpoint, **without** the `local` flag. This will deploy the model to the cloud endpoint that was created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint k8s-endpoint-06190829258926 exists\n",
      "\u001b[32mUploading number_predictor (4.34 MBs): 100%|##########| 4340323/4340323 [00:01<00:00, 2659462.35it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "KubernetesOnlineDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'k8s-endpoint-06190829258926', 'type': 'Kubernetes', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/providers/Microsoft.MachineLearningServices/locations/westeurope/mfeOperationsStatus/odidp:798f953a-277e-4ed7-90e2-0e1cd6d888eb:919dfcea-9109-4ad1-a385-b3434693594b?api-version=2023-04-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/onlineEndpoints/k8s-endpoint-06190829258926/deployments/blue', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\deanv\\\\Dropbox\\\\0_Buas\\\\2023-2024\\\\y2D\\\\Azure Content Testing\\\\Example-App-master\\\\Example-App-master\\\\Notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001A8E764C0A0>, 'model': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/models/example_2/versions/2', 'code_configuration': {'code': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/codes/d51fecbd-3a01-4995-8123-75fbe09c426b/versions/1'}, 'environment': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/environments/CliV2AnonymousEnvironment/versions/361eb1ac6793ec7487f308e39ff4b25f', 'environment_variables': {'AZUREML_MODEL_DIR': '/var/azureml-app/azureml-models/example_2/2', 'SERVICE_PATH_PREFIX': 'api/v1/endpoint/k8s-endpoint-06190829258926', 'SERVICE_NAME': 'k8s-endpoint-06190829258926', 'AZUREML_ENTRY_SCRIPT': 'scoring.py', 'AML_APP_ROOT': '/var/azureml-app/number_predictor'}, 'app_insights_enabled': False, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.TargetUtilizationScaleSettings object at 0x000001A8E764C340>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x000001A8E764F220>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x000001A8E764D900>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x000001A8E764EAA0>, 'instance_count': None, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': None, 'data_collector': None, 'resources': <azure.ai.ml.entities._deployment.resource_requirements_settings.ResourceRequirementsSettings object at 0x000001A8E764D4E0>})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The last step is to route traffic to the deploymennt. We only have 1 deployment (blue), so we can route all traffic to it. We can do this by calling the `endpoint.traffic` method on the endpoint object, and passing in the percentage of traffic that should be routed to the deployment. In this case we will route 100% of the traffic to the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KubernetesOnlineEndpoint({'provisioning_state': 'Succeeded', 'scoring_uri': 'http://194.171.191.227:30397/api/v1/endpoint/k8s-endpoint-06190829258926/score', 'openapi_uri': 'http://194.171.191.227:30397/api/v1/endpoint/k8s-endpoint-06190829258926/swagger.json', 'name': 'k8s-endpoint-06190829258926', 'description': 'this is a sample online endpoint', 'tags': {'Type': 'Review Session'}, 'properties': {'createdBy': 'a2230f31-0fda-428d-8c5c-ec79e91a49f5', 'createdAt': '2024-06-19T06:29:52.864258+0000', 'lastModifiedAt': '2024-06-19T06:29:52.864258+0000', 'azureml.onlineendpointid': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourcegroups/buas-y2/providers/microsoft.machinelearningservices/workspaces/staff-test/onlineendpoints/k8s-endpoint-06190829258926', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/providers/Microsoft.MachineLearningServices/locations/westeurope/mfeOperationsStatus/oeidp:798f953a-277e-4ed7-90e2-0e1cd6d888eb:2ae2b47d-dcc7-443b-8c3f-0135dedfc3be?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/onlineEndpoints/k8s-endpoint-06190829258926', 'Resource__source_path': '', 'base_path': 'c:\\\\Users\\\\deanv\\\\Dropbox\\\\0_Buas\\\\2023-2024\\\\y2D\\\\Azure Content Testing\\\\Example-App-master\\\\Example-App-master\\\\Notebooks', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000001A8E766FEB0>, 'auth_mode': 'key', 'location': 'westeurope', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x000001A8E766D480>, 'traffic': {'blue': 100}, 'mirror_traffic': {}, 'kind': 'K8S', 'compute': '/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/computes/adsai1'})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can check the status of the deployment by looking at the logs of the deployment with the `ml_client`. You can do this by calling the `get_logs` method on the deployment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth_mode: key\n",
      "compute: azureml:/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/computes/adsai1\n",
      "description: this is a sample online endpoint\n",
      "id: /subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourceGroups/buas-y2/providers/Microsoft.MachineLearningServices/workspaces/Staff-Test/onlineEndpoints/k8s-endpoint-06190829258926\n",
      "identity:\n",
      "  principal_id: 9dd64db7-c70c-422b-8214-db43bca9407e\n",
      "  tenant_id: 0a33589b-0036-4fe8-a829-3ed0926af886\n",
      "  type: system_assigned\n",
      "kind: K8S\n",
      "location: westeurope\n",
      "mirror_traffic: {}\n",
      "name: k8s-endpoint-06190829258926\n",
      "openapi_uri: http://194.171.191.227:30397/api/v1/endpoint/k8s-endpoint-06190829258926/swagger.json\n",
      "properties:\n",
      "  AzureAsyncOperationUri: https://management.azure.com/subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/providers/Microsoft.MachineLearningServices/locations/westeurope/mfeOperationsStatus/oeidp:798f953a-277e-4ed7-90e2-0e1cd6d888eb:2ae2b47d-dcc7-443b-8c3f-0135dedfc3be?api-version=2022-02-01-preview\n",
      "  azureml.onlineendpointid: /subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourcegroups/buas-y2/providers/microsoft.machinelearningservices/workspaces/staff-test/onlineendpoints/k8s-endpoint-06190829258926\n",
      "  createdAt: 2024-06-19T06:29:52.864258+0000\n",
      "  createdBy: a2230f31-0fda-428d-8c5c-ec79e91a49f5\n",
      "  lastModifiedAt: 2024-06-19T06:29:52.864258+0000\n",
      "provisioning_state: Succeeded\n",
      "scoring_uri: http://194.171.191.227:30397/api/v1/endpoint/k8s-endpoint-06190829258926/score\n",
      "tags:\n",
      "  Type: Review Session\n",
      "traffic:\n",
      "  blue: 100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception occurred while exporting the data.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\trace_exporter\\__init__.py\", line 228, in emit\n",
      "    self._transmit_from_storage()\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\common\\transport.py\", line 80, in _transmit_from_storage\n",
      "    for blob in self.storage.gets():\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\common\\storage.py\", line 129, in gets\n",
      "    for name in sorted(os.listdir(self.path)):\n",
      "FileNotFoundError: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\deanv\\\\AppData\\\\Local\\\\Temp\\\\opencensus-python-71b954a8-6b7d-43f5-986c-3d3a6605d803'\n",
      "Exception occurred while exporting the data.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\trace_exporter\\__init__.py\", line 228, in emit\n",
      "    self._transmit_from_storage()\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\common\\transport.py\", line 80, in _transmit_from_storage\n",
      "    for blob in self.storage.gets():\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\common\\storage.py\", line 129, in gets\n",
      "    for name in sorted(os.listdir(self.path)):\n",
      "FileNotFoundError: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\deanv\\\\AppData\\\\Local\\\\Temp\\\\opencensus-python-71b954a8-6b7d-43f5-986c-3d3a6605d803'\n",
      "Exception occurred while exporting the data.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\trace_exporter\\__init__.py\", line 228, in emit\n",
      "    self._transmit_from_storage()\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\common\\transport.py\", line 80, in _transmit_from_storage\n",
      "    for blob in self.storage.gets():\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\common\\storage.py\", line 129, in gets\n",
      "    for name in sorted(os.listdir(self.path)):\n",
      "FileNotFoundError: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\deanv\\\\AppData\\\\Local\\\\Temp\\\\opencensus-python-71b954a8-6b7d-43f5-986c-3d3a6605d803'\n",
      "Exception occurred while exporting the data.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\trace_exporter\\__init__.py\", line 228, in emit\n",
      "    self._transmit_from_storage()\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\common\\transport.py\", line 80, in _transmit_from_storage\n",
      "    for blob in self.storage.gets():\n",
      "  File \"C:\\Users\\deanv\\AppData\\Roaming\\Python\\Python310\\site-packages\\opencensus\\ext\\azure\\common\\storage.py\", line 129, in gets\n",
      "    for name in sorted(os.listdir(self.path)):\n",
      "FileNotFoundError: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\deanv\\\\AppData\\\\Local\\\\Temp\\\\opencensus-python-71b954a8-6b7d-43f5-986c-3d3a6605d803'\n"
     ]
    }
   ],
   "source": [
    "status = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-06-16 09:50:37,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:50:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:50:37,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:50:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:50:47,075 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:50:47 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:50:47,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:50:47 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:50:57,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:50:57 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:50:57,083 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:50:57 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:07,075 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:07,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:17,075 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:17,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:27,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:27,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:37,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:37,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:47,075 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:47 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:47,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:47 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:57,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:57 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:51:57,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:51:57 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:07,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:07,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:17,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:17,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:27,075 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:27,075 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:37,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:37,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:47,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:47 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:47,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:47 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:57,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:57 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:52:57,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:52:57 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:07,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:07,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:17,075 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:17,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:27,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:27,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:37,075 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:37,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:47,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:47 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:47,078 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:47 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:57,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:57 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:53:57,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:53:57 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:54:07,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:54:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:54:07,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:54:07 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:54:17,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:54:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:54:17,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:54:17 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:54:27,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:54:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:54:27,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:54:27 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:54:37,076 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:54:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n2024-06-16 09:54:37,077 I [326] gunicorn.access - 127.0.0.1 - - [16/Jun/2024:09:54:37 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"kube-probe/1.29\"\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50\n",
    ")\n",
    "\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue': 100}\n",
      "http://194.171.191.227:30397/api/v1/endpoint/k8s-endpoint-06161121150181/score\n"
     ]
    }
   ],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Cloud Endpoint and Blue Deployment🧪\n",
    "\n",
    "The scoring script for the cloud deployment is the same as the scoring script for the local deployment. It expects a JSON object with a key `data` that contains the data to be scored. The data is a base64 encoded image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "# load image and encode it in base64\n",
    "import base64\n",
    "import json\n",
    "\n",
    "image_path = \"../data/MNIST_44_0.png\"\n",
    "# image_path = \"../data/test_image5.png\"\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "print(base64_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open the deployment in AzureML studio, you can see the status of the deployment, and the logs of the deployment. You can also see the traffic that is being routed to the deployment. If you click on the `consume` tab, you can see the code that you need to use to send data to the endpoint. You can also see the response that you get back from the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:1348\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1303\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1302\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1303\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1349\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1348\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1349\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1298\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:1058\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1061\u001b[39m \n\u001b[32m   1062\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:996\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    995\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:962\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    961\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:851\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[32m0\u001b[39m]\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ExceptionGroup(\u001b[33m\"\u001b[39m\u001b[33mcreate_connection failed\u001b[39m\u001b[33m\"\u001b[39m, exceptions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:836\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    835\u001b[39m     sock.bind(source_address)\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mTimeoutError\u001b[39m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m req = urllib.request.Request(url, body, headers)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     response = \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     result = response.read()\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:519\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    516\u001b[39m     req = meth(req)\n\u001b[32m    518\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    522\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:536\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    535\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:1377\u001b[39m, in \u001b[36mHTTPHandler.http_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\urllib\\request.py:1351\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1348\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1349\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1352\u001b[39m     r = h.getresponse()\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "data = {\n",
    "    \"text\": \"hello there\"\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "#url = 'http://194.171.191.227:30397/api/v1/endpoint/k8s-endpoint-06161121150181/score'\n",
    "# url = 'https://fb77-194-171-191-227.ngrok-free.app/api/v1/endpoint/k8s-endpoint-06190829258926/score'\n",
    "# url = 'http://194.171.191.227:3092/api/v1/endpoint/test-endpoint-06191104713962/score'\n",
    "url = \"http://194.171.191.227:30526/api/v1/endpoint/deberta-endpoint/score\"\n",
    "\n",
    "# url = 'https://fb77-194-171-191-227.ngrok-free.app/api/v1/endpoint/test-endpoint-06191104713962/score'\n",
    "# Replace this with the primary/secondary key, AMLToken, or Microsoft Entra ID token for the endpoint\n",
    "api_key = '5p9ggpJc34NY3FH65JmJgIOiaWsBpre2cBH4r38EnmHsCKt0iuAmJQQJ99BFAAAAAAAAAAAAINFRAZML3sA3'\n",
    "if not api_key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'blue' }\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOU NEED TO INSTALL RUNIT!!!, or use an azure image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-clf-pipeline-bOnCAZAr-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
